{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9508924,
          "sourceType": "datasetVersion",
          "datasetId": 5787852
        }
      ],
      "dockerImageVersionId": 30776,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Введение\n",
        "\n",
        "Этот проект представляет собой реализацию системы для обработки запросов с использованием больших языковых моделей (LLM), таких как Saiga Mistral 7b, с интеграцией популярных библиотек для векторных индексов и эмбеддингов, включая Hugging Face, Llama Index и Langchain.\n",
        "Код позволяет эффективно управлять большими текстовыми данными, структурировать и анализировать их, а также выполнять точные и релевантные ответы на запросы пользователей на основе предобученных моделей и векторных представлений."
      ],
      "metadata": {
        "id": "j2U9xI2UJq1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему Saiga Mistral 7b?\n",
        "\n",
        "Saiga Mistral 7b — это одна из наиболее продвинутых и сбалансированных моделей для выполнения языковых задач, таких как генерация текста, ответы на вопросы и обработка больших объемов данных.\n",
        "\n",
        "Вот несколько причин, почему Saiga Mistral 7b была выбрана для этого проекта:\n",
        "\n",
        "Компактный размер и мощность: Модель содержит 7 миллиардов параметров, что делает её мощной, но одновременно достаточно компактной, чтобы эффективно работать на современных аппаратных платформах с ограниченными ресурсами (в том числе в режиме квантования).\n",
        "\n",
        "Поддержка квантования: В проекте используется квантование для работы с моделью в 4-битном режиме. Это позволяет существенно снизить нагрузку на GPU и ускорить вычисления без значительных потерь в качестве ответов. Saiga Mistral 7b поддерживает методы, такие как bnb_4bit и nf4, для этого сценария.\n",
        "\n",
        "Качество генерации текста: Модель демонстрирует отличные результаты в задачах генерации связного и осмысленного текста, что важно для систем обработки естественного языка, требующих высокой степени контекстуального понимания.\n",
        "\n",
        "Гибкость дообучения: Модель совместима с методами дообучения, такими как PEFT и LoRA, что делает её легко адаптируемой к специфическим задачам и данным.\n",
        "\n",
        "Русскоязычная поддержка: Saiga Mistral 7b показывает отличные результаты на русскоязычных данных, что критично для проектов, ориентированных на русскоязычную аудиторию."
      ],
      "metadata": {
        "id": "AJSzHh3GJq1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Установка библиотек"
      ],
      "metadata": {
        "id": "KoFe3qZgJq1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install llama_index pyvis Ipython langchain pypdf langchain_community\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-embeddings-langchain\n",
        "!pip install langchain-huggingface\n",
        "!pip install sentencepiece accelerate\n",
        "!pip install -U bitsandbytes\n",
        "!pip install peft\n",
        "!pip install openai"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-30T15:34:06.004399Z",
          "iopub.execute_input": "2024-09-30T15:34:06.004921Z",
          "iopub.status.idle": "2024-09-30T15:37:13.037037Z",
          "shell.execute_reply.started": "2024-09-30T15:34:06.004887Z",
          "shell.execute_reply": "2024-09-30T15:37:13.035911Z"
        },
        "trusted": true,
        "id": "3O4toP8IJq1h",
        "outputId": "f379fde8-f004-4e19-d491-554b36a22ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-89iz6z63\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-89iz6z63\n  Resolved https://github.com/huggingface/transformers to commit 1dba608df93ffb10a9c268ef35191adf2424c5ca\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2.32.3)\nCollecting tokenizers<0.21,>=0.20 (from transformers==4.46.0.dev0)\n  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.46.0.dev0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\nDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=9924497 sha256=0bb0d349b2900641a473becedd923c58812aad6d13a9a3a72bc159614877f2d5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-22kh7gzd/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\nSuccessfully built transformers\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed tokenizers-0.20.0 transformers-4.46.0.dev0\nCollecting llama_index\n  Downloading llama_index-0.11.14-py3-none-any.whl.metadata (11 kB)\nCollecting pyvis\n  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: Ipython in /opt/conda/lib/python3.10/site-packages (8.21.0)\nCollecting langchain\n  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (5.0.0)\nCollecting langchain_community\n  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama_index)\n  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-cli<0.4.0,>=0.3.1 (from llama_index)\n  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core<0.12.0,>=0.11.14 (from llama_index)\n  Downloading llama_index_core-0.11.14-py3-none-any.whl.metadata (2.4 kB)\nCollecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama_index)\n  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\nCollecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama_index)\n  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai<0.3.0,>=0.2.9 (from llama_index)\n  Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl.metadata (648 bytes)\nCollecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama_index)\n  Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama_index)\n  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\nCollecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama_index)\n  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama_index)\n  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index-readers-llama-parse>=0.3.0 (from llama_index)\n  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\nCollecting nltk>3.8.1 (from llama_index)\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.10/site-packages (from pyvis) (3.1.4)\nCollecting jsonpickle>=1.4.1 (from pyvis)\n  Downloading jsonpickle-3.3.0-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.10/site-packages (from pyvis) (3.3)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from Ipython) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from Ipython) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from Ipython) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from Ipython) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from Ipython) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from Ipython) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from Ipython) (5.14.3)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from Ipython) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from Ipython) (4.9.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.9.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from pypdf) (4.12.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->Ipython) (0.8.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.6->langchain)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nCollecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.14->llama_index) (1.2.14)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.14->llama_index)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.14->llama_index) (2024.6.1)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.14->llama_index) (1.6.0)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.14->llama_index) (10.3.0)\nCollecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.14->llama_index)\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.14->llama_index) (4.66.4)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.14->llama_index) (1.16.0)\nCollecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index)\n  Downloading llama_cloud-0.1.0-py3-none-any.whl.metadata (750 bytes)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.2)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.12.3)\nCollecting pypdf\n  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nCollecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama_index)\n  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama_index) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama_index) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama_index) (2024.5.15)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->Ipython) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->Ipython) (0.2.13)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->Ipython) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->Ipython) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->Ipython) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->Ipython) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (2.5)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (2.4)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.9.0)\nCollecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.1)\nDownloading llama_index-0.11.14-py3-none-any.whl (6.8 kB)\nDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jsonpickle-3.3.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\nDownloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\nDownloading llama_index_core-0.11.14-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\nDownloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_llms_openai-0.2.9-py3-none-any.whl (12 kB)\nDownloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl (5.9 kB)\nDownloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\nDownloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\nDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\nDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading llama_cloud-0.1.0-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_parse-0.5.6-py3-none-any.whl (10 kB)\nDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: striprtf, dirtyjson, pypdf, packaging, nltk, jsonpickle, jiter, tiktoken, pydantic-settings, openai, llama-cloud, langsmith, pyvis, llama-index-legacy, llama-index-core, langchain-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, langchain_community, llama-index-question-gen-openai, llama_index\n  Attempting uninstall: pypdf\n    Found existing installation: pypdf 5.0.0\n    Uninstalling pypdf-5.0.0:\n      Successfully uninstalled pypdf-5.0.0\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dirtyjson-1.0.8 jiter-0.5.0 jsonpickle-3.3.0 langchain-0.3.1 langchain-core-0.3.6 langchain-text-splitters-0.3.0 langchain_community-0.3.1 langsmith-0.1.129 llama-cloud-0.1.0 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.14 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.9 llama-index-multi-modal-llms-openai-0.2.1 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.6 llama_index-0.11.14 nltk-3.9.1 openai-1.50.2 packaging-24.1 pydantic-settings-2.5.2 pypdf-4.3.1 pyvis-0.3.2 striprtf-0.0.26 tiktoken-0.7.0\nCollecting llama-index-llms-huggingface\n  Downloading llama_index_llms_huggingface-0.3.4-py3-none-any.whl.metadata (840 bytes)\nCollecting huggingface-hub<0.24.0,>=0.23.0 (from llama-index-llms-huggingface)\n  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-llms-huggingface) (0.11.14)\nCollecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-llms-huggingface) (2.4.0)\nRequirement already satisfied: transformers<5.0.0,>=4.37.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.46.0.dev0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.9.5)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.2.14)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.8)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.27.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.3)\nRequirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (10.3.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.9.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.3.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.7.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.20.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\nRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.34.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (4.0.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.22.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.2.0)\nDownloading llama_index_llms_huggingface-0.3.4-py3-none-any.whl (11 kB)\nDownloading huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading text_generation-0.7.0-py3-none-any.whl (12 kB)\nInstalling collected packages: huggingface-hub, text-generation, llama-index-llms-huggingface\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.25.0\n    Uninstalling huggingface-hub-0.25.0:\n      Successfully uninstalled huggingface-hub-0.25.0\nSuccessfully installed huggingface-hub-0.23.5 llama-index-llms-huggingface-0.3.4 text-generation-0.7.0\nCollecting llama-index-embeddings-huggingface\n  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\nRequirement already satisfied: huggingface-hub>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.23.5)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.11.14)\nCollecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\nCollecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n  Downloading minijinja-2.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.30)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.3)\nRequirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.3.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.9.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.3.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.16.0)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.0.dev0)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.5.15)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.22.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\nDownloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\nDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading minijinja-2.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (861 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m861.9/861.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: minijinja, sentence-transformers, llama-index-embeddings-huggingface\nSuccessfully installed llama-index-embeddings-huggingface-0.3.1 minijinja-2.2.0 sentence-transformers-3.1.1\nCollecting llama-index-embeddings-langchain\n  Downloading llama_index_embeddings_langchain-0.2.1-py3-none-any.whl.metadata (612 bytes)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-langchain) (0.11.14)\nRequirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.9.5)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.2.14)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.0.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2024.6.1)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.27.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.3)\nRequirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (10.3.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.9.2)\nRequirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (8.3.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.7.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.12.2)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.0.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2024.5.15)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.22.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.14.0)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (24.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.2.0)\nDownloading llama_index_embeddings_langchain-0.2.1-py3-none-any.whl (2.5 kB)\nInstalling collected packages: llama-index-embeddings-langchain\nSuccessfully installed llama-index-embeddings-langchain-0.2.1\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain-huggingface) (0.23.5)\nRequirement already satisfied: langchain-core<0.4,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain-huggingface) (0.3.6)\nRequirement already satisfied: sentence-transformers>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from langchain-huggingface) (3.1.1)\nRequirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain-huggingface) (0.20.0)\nRequirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain-huggingface) (4.46.0.dev0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.129)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.9.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.3.0)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.3.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.4)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.2.0)\nDownloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: langchain-huggingface\nSuccessfully installed langchain-huggingface-0.1.0\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.5)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.0\nCollecting peft\n  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (24.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.46.0.dev0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.0\nRequirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.50.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.5.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.9.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт библиотек"
      ],
      "metadata": {
        "id": "qk-1KVQSJq1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:37:13.039198Z",
          "iopub.execute_input": "2024-09-30T15:37:13.039585Z",
          "iopub.status.idle": "2024-09-30T15:37:13.045066Z",
          "shell.execute_reply.started": "2024-09-30T15:37:13.039547Z",
          "shell.execute_reply": "2024-09-30T15:37:13.043966Z"
        },
        "trusted": true,
        "id": "B7eBthooJq1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, Document, GPTVectorStoreIndex\n",
        "from llama_index.core import Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "import torch\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:37:13.046206Z",
          "iopub.execute_input": "2024-09-30T15:37:13.046518Z",
          "iopub.status.idle": "2024-09-30T15:37:34.105699Z",
          "shell.execute_reply.started": "2024-09-30T15:37:13.046484Z",
          "shell.execute_reply": "2024-09-30T15:37:34.104916Z"
        },
        "trusted": true,
        "id": "6HVturkuJq1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Аутентификация HF и OpenAI"
      ],
      "metadata": {
        "id": "d5n8LueiJq1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import getpass\n",
        "HF_TOKEN = getpass.getpass(\"Вставьте ваш токен: \")\n",
        "\n",
        "# Выполняем аутентификацию\n",
        "login(HF_TOKEN, add_to_git_credential=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:37:34.107910Z",
          "iopub.execute_input": "2024-09-30T15:37:34.108531Z",
          "iopub.status.idle": "2024-09-30T15:39:16.453137Z",
          "shell.execute_reply.started": "2024-09-30T15:37:34.108495Z",
          "shell.execute_reply": "2024-09-30T15:39:16.452224Z"
        },
        "trusted": true,
        "id": "VVAxaMOwJq1k",
        "outputId": "6ef9c262-2aa7-4b1e-f22d-cb2337c816e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Вставьте ваш токен:  ·····································\n"
        },
        {
          "name": "stdout",
          "text": "Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass # для работы с паролями\n",
        "import os      # для работы с окружением и файловой системой\n",
        "\n",
        "# Запрос ввода ключа от OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:39:16.454214Z",
          "iopub.execute_input": "2024-09-30T15:39:16.454499Z",
          "iopub.status.idle": "2024-09-30T15:39:21.663903Z",
          "shell.execute_reply.started": "2024-09-30T15:39:16.454467Z",
          "shell.execute_reply": "2024-09-30T15:39:21.663146Z"
        },
        "trusted": true,
        "id": "Na2GlbG-Jq1k",
        "outputId": "c6e446d0-74cf-475e-a4e3-5944a608c9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Введите OpenAI API Key: ···················································\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как языковая модель saiga_mistral_7b_lora обучена для ведения диалогов, то для нее определены специальные теги.\n",
        "\n",
        "Сообщения к модели строиться по шаблону:\n",
        "\n",
        "< s >{role}\\n{content}< /s >,\n",
        "\n",
        "где content - это текст сообщения к модели, role - одна из возможных ролей:\n",
        "\n",
        "system - системная роль, определяет преднастройки модели\n",
        "user - вопросы от пользователей"
      ],
      "metadata": {
        "id": "vGh4M8AuJq1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_to_prompt(messages):\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "            prompt += f\"<s>{message.role}\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'user':\n",
        "            prompt += f\"<s>{message.role}\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'bot':\n",
        "            prompt += f\"<s>bot\\n\"\n",
        "\n",
        "    # ensure we start with a system prompt, insert blank if needed\n",
        "    if not prompt.startswith(\"<s>system\\n\"):\n",
        "        prompt = \"<s>system\\n</s>\\n\" + prompt\n",
        "\n",
        "    # add final assistant prompt\n",
        "    prompt = prompt + \"<s>bot\\n\"\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    return f\"<s>system\\n</s>\\n<s>user\\n{completion}</s>\\n<s>bot\\n\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:39:21.665029Z",
          "iopub.execute_input": "2024-09-30T15:39:21.665420Z",
          "iopub.status.idle": "2024-09-30T15:39:21.675214Z",
          "shell.execute_reply.started": "2024-09-30T15:39:21.665371Z",
          "shell.execute_reply": "2024-09-30T15:39:21.674166Z"
        },
        "trusted": true,
        "id": "Ro76rH8eJq1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка модели"
      ],
      "metadata": {
        "id": "IkJy8nkFJq1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализована поддержка дообучения модели через PEFT (Parameter-Efficient Fine-Tuning) с использованием метода LoRA, что позволяет адаптировать модель под специфические задачи с минимальными вычислительными затратами"
      ],
      "metadata": {
        "id": "ipICGSO8Jq1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "# Определяем параметры квантования, иначе модель не выполниться в колабе\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Задаем имя модели\n",
        "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
        "\n",
        "# Создание конфига, соответствующего методу PEFT (в нашем случае LoRA)\n",
        "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Загружаем базовую модель, ее имя берем из конфига для LoRA\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,          # идентификатор модели\n",
        "    quantization_config=quantization_config, # параметры квантования\n",
        "    torch_dtype=torch.float16,               # тип данных\n",
        "    device_map=\"auto\"                        # автоматический выбор типа устройства\n",
        ")\n",
        "\n",
        "# Загружаем LoRA модель\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Переводим модель в режим инференса\n",
        "# Можно не переводить, но явное всегда лучше неявного\n",
        "model.eval()\n",
        "\n",
        "# Загружаем токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:39:21.676534Z",
          "iopub.execute_input": "2024-09-30T15:39:21.676923Z",
          "iopub.status.idle": "2024-09-30T15:40:56.014373Z",
          "shell.execute_reply.started": "2024-09-30T15:39:21.676887Z",
          "shell.execute_reply": "2024-09-30T15:40:56.013542Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "6cef6e48dcf245b98ac48d8fd81dec02",
            "adfc1a65496745ff839f0d282ebd781a",
            "356c3d78618b45bcb71955ce9955308f",
            "78824b6eb3e14c94add5e4c7c48c5a32",
            "566de9539efd43cb979176a34f9739ae",
            "1042eb60b19842238b8dbf8c06e0d42d",
            "1faf546d607c460499a6a1bb32d30ae4",
            "6807eb8662ab4333a1d14fef86c63fd4",
            "d146bc61573b491c9157dc83ebe51722",
            "64e0177f86b44cf8839979acdd302b08",
            "f3c0b1020959417fb85e474ac6c0c3bc",
            "153f3a7e6f654da2af7948b4910857e9",
            "13b96b6872ac4dbf9aaee165144df29f"
          ]
        },
        "id": "b-tYPb9rJq1l",
        "outputId": "5f6a2e19-22e7-4d9a-929f-6cb9780b4005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cef6e48dcf245b98ac48d8fd81dec02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/623 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adfc1a65496745ff839f0d282ebd781a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "356c3d78618b45bcb71955ce9955308f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78824b6eb3e14c94add5e4c7c48c5a32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "566de9539efd43cb979176a34f9739ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1042eb60b19842238b8dbf8c06e0d42d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1faf546d607c460499a6a1bb32d30ae4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6807eb8662ab4333a1d14fef86c63fd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/54.6M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d146bc61573b491c9157dc83ebe51722"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64e0177f86b44cf8839979acdd302b08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3c0b1020959417fb85e474ac6c0c3bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "153f3a7e6f654da2af7948b4910857e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13b96b6872ac4dbf9aaee165144df29f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод конфигурации для модели"
      ],
      "metadata": {
        "id": "8sCXC9bwJq1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "print(generation_config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:40:56.015642Z",
          "iopub.execute_input": "2024-09-30T15:40:56.016626Z",
          "iopub.status.idle": "2024-09-30T15:40:56.191926Z",
          "shell.execute_reply.started": "2024-09-30T15:40:56.016586Z",
          "shell.execute_reply": "2024-09-30T15:40:56.190972Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "8218e48b8da440d4a712897d9c595191"
          ]
        },
        "id": "Kvw2AM4LJq1l",
        "outputId": "ae66e9bb-d65a-4104-94d3-bb0622886ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8218e48b8da440d4a712897d9c595191"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "GenerationConfig {\n  \"bos_token_id\": 1,\n  \"do_sample\": true,\n  \"eos_token_id\": 2,\n  \"max_new_tokens\": 1536,\n  \"no_repeat_ngram_size\": 15,\n  \"pad_token_id\": 0,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.2,\n  \"top_k\": 40,\n  \"top_p\": 0.9\n}\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    model=model,             # модель\n",
        "    model_name=MODEL_NAME,   # идентификатор модели\n",
        "    tokenizer=tokenizer,     # токенизатор\n",
        "    max_new_tokens=generation_config.max_new_tokens, # параметр необходимо использовать здесь, и не использовать в generate_kwargs, иначе ошибка двойного использования\n",
        "    model_kwargs={\"quantization_config\": quantization_config}, # параметры квантования\n",
        "    generate_kwargs = {   # параметры для инференса\n",
        "      \"bos_token_id\": generation_config.bos_token_id, # токен начала последовательности\n",
        "      \"eos_token_id\": generation_config.eos_token_id, # токен окончания последовательности\n",
        "      \"pad_token_id\": generation_config.pad_token_id, # токен пакетной обработки (указывает, что последовательность ещё не завершена)\n",
        "      \"no_repeat_ngram_size\": generation_config.no_repeat_ngram_size,\n",
        "      \"repetition_penalty\": generation_config.repetition_penalty,\n",
        "      \"temperature\": generation_config.temperature,\n",
        "      \"do_sample\": True,\n",
        "      \"top_k\": 50,\n",
        "      \"top_p\": 0.95\n",
        "    },\n",
        "    messages_to_prompt=messages_to_prompt,     # функция для преобразования сообщений к внутреннему формату\n",
        "    completion_to_prompt=completion_to_prompt, # функции для генерации текста\n",
        "    device_map=\"auto\",                         # автоматически определять устройство\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:40:56.193063Z",
          "iopub.execute_input": "2024-09-30T15:40:56.193354Z",
          "iopub.status.idle": "2024-09-30T15:40:56.626701Z",
          "shell.execute_reply.started": "2024-09-30T15:40:56.193323Z",
          "shell.execute_reply": "2024-09-30T15:40:56.625798Z"
        },
        "trusted": true,
        "id": "v7FNdCQLJq1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Работа с базой данных"
      ],
      "metadata": {
        "id": "Gp1S0fprJq1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Векторизация данных производится с использованием многозадачных эмбеддингов sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2, что обеспечивает поддержку нескольких языков, включая русский"
      ],
      "metadata": {
        "id": "sbrtGB2WJq1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface  import HuggingFaceEmbeddings\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:40:56.631083Z",
          "iopub.execute_input": "2024-09-30T15:40:56.631843Z",
          "iopub.status.idle": "2024-09-30T15:41:02.715195Z",
          "shell.execute_reply.started": "2024-09-30T15:40:56.631803Z",
          "shell.execute_reply": "2024-09-30T15:41:02.714236Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "58cfc9a064174fb08633c013d22e40c5",
            "ed1bcb4e30fb4ef58c57fd29fa690b7b",
            "625f6a3923d644c9b2e46248318202b5",
            "73e6d33b87b941938353e58e5eeb82bf",
            "8ef761a1daa34c62a4d94c0dd69139d0",
            "7a14373d922349329a2399032a4ce614",
            "08af67b9455b4587a6a517faedfe860b",
            "5146fb30bf6b40cfb1de593b2c00a221",
            "79ae6e3cc72641378abc0763b0a0867e",
            "cb140662331a4916ab04e12bc3084700"
          ]
        },
        "id": "MUEKzsDqJq1m",
        "outputId": "6416bda5-a8ad-4c79-c195-136659c0c666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58cfc9a064174fb08633c013d22e40c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed1bcb4e30fb4ef58c57fd29fa690b7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "625f6a3923d644c9b2e46248318202b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73e6d33b87b941938353e58e5eeb82bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ef761a1daa34c62a4d94c0dd69139d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a14373d922349329a2399032a4ce614"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08af67b9455b4587a6a517faedfe860b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5146fb30bf6b40cfb1de593b2c00a221"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79ae6e3cc72641378abc0763b0a0867e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb140662331a4916ab04e12bc3084700"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройка ServiceContext (глобальная настройка параметров LLM)\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:41:02.716466Z",
          "iopub.execute_input": "2024-09-30T15:41:02.717237Z",
          "iopub.status.idle": "2024-09-30T15:41:03.722000Z",
          "shell.execute_reply.started": "2024-09-30T15:41:02.717200Z",
          "shell.execute_reply": "2024-09-30T15:41:03.721145Z"
        },
        "trusted": true,
        "id": "pWvXjv19Jq1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rNhJPFBEJq1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработка текстов и структурирования данных, включая возможность извлечения табличной информации из текстовых документов"
      ],
      "metadata": {
        "id": "swyK3lNxJq1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def extract_structured_data(text):\n",
        "\n",
        "    tables = []\n",
        "    table_pattern = re.compile(r'(\\d+(?:\\.\\d+)?(?:\\s+|,|\\t)\\d+(?:\\.\\d+)?(?:\\s+|,|\\t)\\d+(?:\\.\\d+)?(?:\\s+|,|\\t)\\d+)')\n",
        "\n",
        "    for match in table_pattern.finditer(text):\n",
        "        table_data = match.group(0)\n",
        "        # Разделение строки на столбцы по пробелам или запятым\n",
        "        columns = re.split(r'\\s+|,|\\t', table_data)\n",
        "        tables.append(columns)\n",
        "\n",
        "    if tables:\n",
        "        # Преобразуем в DataFrame для структурированного хранения\n",
        "        df = pd.DataFrame(tables)\n",
        "        return df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def preprocess_document(doc):\n",
        "    if len(doc.text) < 100:  # Фильтрация по длине документа\n",
        "        return None\n",
        "\n",
        "    # Извлекаем структурированные данные из текста\n",
        "    structured_data = extract_structured_data(doc.text)\n",
        "\n",
        "    # Если данные представлены в виде DataFrame, преобразуем их в список\n",
        "    if isinstance(structured_data, pd.DataFrame):\n",
        "        structured_data = structured_data.to_dict(orient=\"list\")  # Преобразуем в сериализуемый формат\n",
        "\n",
        "    # Возвращаем объект Document с текстом и метаданными\n",
        "    return Document(text=doc.text, metadata={\"structured_data\": structured_data})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:41:03.723317Z",
          "iopub.execute_input": "2024-09-30T15:41:03.723729Z",
          "iopub.status.idle": "2024-09-30T15:41:03.732952Z",
          "shell.execute_reply.started": "2024-09-30T15:41:03.723675Z",
          "shell.execute_reply": "2024-09-30T15:41:03.731979Z"
        },
        "trusted": true,
        "id": "SV60c_v9Jq1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для примера работы загружается книга \"Архитектура компьютера\""
      ],
      "metadata": {
        "id": "b6PT_O4UJq1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и предобработка документов\n",
        "documents = [preprocess_document(doc) for doc in SimpleDirectoryReader('/kaggle/input/tanebaum-ostin').load_data() if doc]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:43:04.773274Z",
          "iopub.execute_input": "2024-09-30T15:43:04.773727Z",
          "iopub.status.idle": "2024-09-30T15:44:53.895850Z",
          "shell.execute_reply.started": "2024-09-30T15:43:04.773686Z",
          "shell.execute_reply": "2024-09-30T15:44:53.895005Z"
        },
        "trusted": true,
        "id": "QjxTKaEfJq1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Фильтрация None значений после предобработки\n",
        "documents = [doc for doc in documents if doc is not None]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:45:26.815693Z",
          "iopub.execute_input": "2024-09-30T15:45:26.816615Z",
          "iopub.status.idle": "2024-09-30T15:45:26.821271Z",
          "shell.execute_reply.started": "2024-09-30T15:45:26.816573Z",
          "shell.execute_reply": "2024-09-30T15:45:26.820334Z"
        },
        "trusted": true,
        "id": "rOwose2vJq1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Система использует GPTVectorStoreIndex для создания векторных представлений документов, что позволяет эффективно искать и извлекать информацию на основе сходства текстов"
      ],
      "metadata": {
        "id": "bfjvP189Jq1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = GPTVectorStoreIndex.from_documents(\n",
        "\tdocuments\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:45:29.639815Z",
          "iopub.execute_input": "2024-09-30T15:45:29.640212Z",
          "iopub.status.idle": "2024-09-30T15:45:43.275195Z",
          "shell.execute_reply.started": "2024-09-30T15:45:29.640176Z",
          "shell.execute_reply": "2024-09-30T15:45:43.274367Z"
        },
        "trusted": true,
        "id": "LTpluZUdJq1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фильтрация запроса по длинне символов"
      ],
      "metadata": {
        "id": "pguev006Jq1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_query(query, min_length=10, max_length=100):\n",
        "    \"\"\"\n",
        "    Функция классифицирует запрос на короткий, длинный или пустой.\n",
        "\n",
        "    Аргументы:\n",
        "    - query: строка запроса.\n",
        "    - min_length: минимальная длина для \"корректного\" запроса.\n",
        "    - max_length: максимальная длина для \"корректного\" запроса.\n",
        "\n",
        "    Возвращает:\n",
        "    - строка с результатом классификации.\n",
        "    \"\"\"\n",
        "    # Удаляем лишние пробелы\n",
        "    query = query.strip()\n",
        "\n",
        "    # Проверка на пустой запрос\n",
        "    if not query:\n",
        "        return \"Запрос пуст.\"\n",
        "\n",
        "    # Проверка на короткий запрос\n",
        "    if len(query) < min_length:\n",
        "        return f\"Запрос слишком короткий. Длина запроса: {len(query)} символов.\"\n",
        "\n",
        "    # Проверка на длинный запрос\n",
        "    if len(query) > max_length:\n",
        "        return f\"Запрос слишком длинный. Длина запроса: {len(query)} символов.\"\n",
        "\n",
        "    return \"Запрос корректный.\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:45:53.034091Z",
          "iopub.execute_input": "2024-09-30T15:45:53.034967Z",
          "iopub.status.idle": "2024-09-30T15:45:53.041584Z",
          "shell.execute_reply.started": "2024-09-30T15:45:53.034925Z",
          "shell.execute_reply": "2024-09-30T15:45:53.040456Z"
        },
        "trusted": true,
        "id": "i04-JJmqJq1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка работы модели"
      ],
      "metadata": {
        "id": "ud9eTgAPJq1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример запроса"
      ],
      "metadata": {
        "id": "H3y90r13Jq1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Серверы работают под управлением каких операционных систем? Поддерживаются ли UNIX и Windows?\"\n",
        "classify_query(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:45:56.527099Z",
          "iopub.execute_input": "2024-09-30T15:45:56.527836Z",
          "iopub.status.idle": "2024-09-30T15:45:56.534535Z",
          "shell.execute_reply.started": "2024-09-30T15:45:56.527770Z",
          "shell.execute_reply": "2024-09-30T15:45:56.533611Z"
        },
        "trusted": true,
        "id": "1t11VhsJJq1o",
        "outputId": "f43791c3-125b-45c3-892b-8ae28639acb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Запрос корректный.'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример ответа"
      ],
      "metadata": {
        "id": "ZLRUwQT9Jq1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=10\n",
        ")\n",
        "\n",
        "message_template = f\"\"\"<s>system\n",
        "Ты являешься моделью, которая отвечает только на основании предоставленных источников.\n",
        "Отвечай строго на основе информации из текста.\n",
        "Если нужной информации нет в источнике, ответь: 'я не знаю'. Не добавляй ничего, что не указано в тексте. Не придумывай и не добавляй лишние данные.\n",
        "\n",
        "<s>user\n",
        "Вопрос: {query}\n",
        "Источник:\n",
        "</s>\n",
        "\"\"\"\n",
        "#\n",
        "response = query_engine.query(message_template)\n",
        "#\n",
        "print()\n",
        "print('Ответ:')\n",
        "print(response.response)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-30T15:46:00.321436Z",
          "iopub.execute_input": "2024-09-30T15:46:00.322340Z",
          "iopub.status.idle": "2024-09-30T15:46:50.176871Z",
          "shell.execute_reply.started": "2024-09-30T15:46:00.322298Z",
          "shell.execute_reply": "2024-09-30T15:46:50.175769Z"
        },
        "trusted": true,
        "id": "qef7h_PaJq1o",
        "outputId": "6470bafc-fc2b-4115-c93c-ca8c68d41f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nОтвет:\nСерверы могут работать под управлением различных операционных систем, включая Unix-like и Windows. Выбор операционной системы зависит от многих факторов, таких как цель сервера, его функциональность, требования к безопасности и многое другое.\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}